dataset,models,projected_tables,completion_tables,tf_removals,tf_keep_rates,tuple_removal_table,tuple_removal_keep_rate,removal_method,removal_attr,removal_attr_values,removal_attr_bias,seed,cascading_deletes,model_families,training_times,query_plan,execution_time,evaluation,fully_synthetic,model_selection_strategy,validation_tuple_removal_keep_rate,validation_removal_attr_bias,validation_tf_keep_rate,not_synthetic,ann_batch_size,ann_neighbors_considered,completable_tables,fixed_completion_path,execution_stats,top_path_union_strategy,prefer_baseline,code_comment,evaluation_method
imdb,['ssar_ep30'],"['movie', 'movie_companies', 'company', 'movie_director', 'director', 'movie_actor', 'actor']",['movie'],"['company.tf_movie_companies.company_id', 'director.tf_movie_director.person_id', 'actor.tf_movie_actor.person_id']","[0.2, 0.2, 0.2]",['movie'],[0.8],['categorical_prob_bias'],['movie.country'],['14'],[0.6],0,True,"['SSARModel(relations=actor-movie_actor,movie-movie_actor)\n\tCompletionSetup(movie_actor->movie, evidence=actor-movie_actor)\n\tCompletionSetup(actor->movie_actor)\n\tHierarchy(actor.id, movie.id, movie.kind_id, movie.production_year, movie.runtime, movie.genre, movie.country, movie.rating, movie.tf_movie_companies.movie_id, movie.tf_movie_actor.movie_id, movie.tf_movie_director.movie_id, movie_actor.person_role_id)_SSARModel(relations=actor-movie_actor,movie-movie_actor)\n\tCompletionSetup(movie_actor->movie, evidence=actor-movie_actor)\n\tCompletionSetup(actor->movie_actor)\n\tHierarchy(actor.id, movie.id, movie.kind_id, movie.production_year, movie.runtime, movie.genre, movie.country, movie.rating, movie.tf_movie_companies.movie_id, movie.tf_movie_actor.movie_id, movie.tf_movie_director.movie_id, movie_actor.person_role_id)']",[[416.96438292227685]],"TopPathUnion(combine,LoadCompleteTable(actor),JoinRelationship(actor-movie_actor, inverse=False, model=ssarc03fd58a5fa43d35004dd6909c64c4d7ae062b177bac94309693fff0),JoinRelationship(movie-movie_actor, inverse=True, model=ssarc03fd58a5fa43d35004dd6909c64c4d7ae062b177bac94309693fff0),ApproximateNearestNeighbor(batch_size=1000, neighbors_considered=10000, r=actor-movie_actor, replace_join_relationships=movie-movie_actor),ApproximateNearestNeighbor(batch_size=1000, neighbors_considered=10000, r=movie-movie_actor, replace_join_relationships=),ProjectRequestedJoin(all_r=actor-movie_actor,movie-movie_actor, tables=movie))",441.60659465007484,"[(False, <RemovalMethod.CATEGORICAL_PROB_BIAS: 'categorical_prob_bias'>, 'movie.country', 0.043433851598476285, 0.0399284226625097, 0.03475417051664404, 2313013, 1849398, 3103004.8900774186), (True, <RemovalMethod.CATEGORICAL_PROB_BIAS: 'categorical_prob_bias'>, 'movie.country', 0.04007973592093388, 0.0399284226625097, 0.032037342162904006, 2042989, 1632703, 3103004.8900774186)]",False,none,[0.4],[0.4],1.0,True,1000,10000,['movie'],"['actor', 'movie_actor', 'movie']","[[{}, {'output_tuples': 31816884, 'input_tuples': 2695356, 'elapsed_time': 193.47309877350926, 'step': 'JoinRelationship(actor-movie_actor, inverse=False, model=ssarc03fd58a5fa43d35004dd6909c64c4d7ae062b177bac94309693fff0)'}, {'output_tuples': 31816874, 'input_tuples': 31816884, 'elapsed_time': 170.7926877392456, 'step': 'JoinRelationship(movie-movie_actor, inverse=True, model=ssarc03fd58a5fa43d35004dd6909c64c4d7ae062b177bac94309693fff0)'}, {'replaced_tuples': 0, 'input_tuples': 0, 'elapsed_time': 0, 'step': 'ApproximateNearestNeighbor(batch_size=1000, neighbors_considered=10000, r=actor-movie_actor, replace_join_relationships=movie-movie_actor)'}, {'replaced_tuples': 97736.0, 'input_tuples': 31816874, 'elapsed_time': 76.17651506140828, 'step': 'ApproximateNearestNeighbor(batch_size=1000, neighbors_considered=10000, r=movie-movie_actor, replace_join_relationships=)'}, {'fan_out_tuple_factors': ['tf_movie_actor.movie_id'], 'input_tuples': 31816874, 'elapsed_time': 1.1198010435327888, 'step': 'ProjectRequestedJoin(all_r=actor-movie_actor,movie-movie_actor, tables=movie)'}]]",combine,False,Now numba discretizing & efficient ANN (no repeat),relative_error
